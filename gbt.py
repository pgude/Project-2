# -*- coding: utf-8 -*-
"""gbt

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i_fvGFIjb12_v1-fECbHD-Rgz4SmjSSK
"""

import numpy as np
import matplotlib.pyplot as plt

class gbt: # Implimenting The GBT class
    # Factors For GBT
    def __init__(self, num_est=100, learn_quan=0.1, high_dep=3, vis_process=False):
        self.num_est = num_est
        self.learn_quan = learn_quan
        self.high_dep = high_dep
        self.vis_process = vis_process
        self.bost_tree = []
        self.score_important = None
        self.start_predict = None

    def grow(self, X, differences, dep, important_score):
        num_sam, num_feature = X.shape
        if dep == 0 or num_sam <= 1:
            return np.mean(differences)
        rec_spliting = None
        small_error = float('inf')

        for feature in range(num_feature):
            cross_threshold = np.unique(X[:, feature])
            for t_shold in cross_threshold:
                left_spilt = X[:, feature] <= t_shold
                right_spilt = ~left_spilt
                if np.sum(left_spilt) == 0 or np.sum(right_spilt) == 0:
                    continue
                left_changes = differences[left_spilt]
                right_changes = differences[right_spilt]
                residuals = (np.var(left_changes) * len(left_changes) +
                         np.var(right_changes) * len(right_changes))
                if residuals < small_error:
                    small_error = residuals
                    rec_spliting = {
                        "feature": feature,
                        "t_shold": t_shold,
                        "left_spilt": left_spilt,
                        "right_spilt": right_spilt
                    }

        if rec_spliting is None:
            return np.mean(differences)
        important_score[rec_spliting["feature"]] += small_error

        left_tree = self.grow(X[rec_spliting["left_spilt"]], differences[rec_spliting["left_spilt"]], dep - 1, important_score)
        right_tree = self.grow(X[rec_spliting["right_spilt"]], differences[rec_spliting["right_spilt"]], dep - 1, important_score)
        return {"feature": rec_spliting["feature"], "t_shold": rec_spliting["t_shold"], "left": left_tree, "right": right_tree}

    def _predict_(self, x, gbt_tree):
        if isinstance(gbt_tree, dict):
            if x[gbt_tree["feature"]] <= gbt_tree["t_shold"]:
                return self._predict_(x, gbt_tree["left"])
            else:
                return self._predict_(x, gbt_tree["right"])
        else:
            return gbt_tree

    def fit(self, X, y):
        self.score_important = np.zeros(X.shape[1])
        self.start_predict = np.mean(y)
        estimators = np.full(y.shape, self.start_predict)
        self.train_residuals = []

        for i in range(self.num_est):
            differences = y - estimators
            gbt_tree = self.grow(X, differences, self.high_dep, self.score_important)
            self.bost_tree.append(gbt_tree)
            estimators += self.learn_quan * np.array([self._predict_(x, gbt_tree) for x in X])

            # Storing The Train Error For MSE
            mse = np.mean((y - estimators) ** 2)
            self.train_residuals.append(mse)

            if self.vis_process:
                print(f"Showing The Epoch Of {i+1}, MSE: {mse}")

        self.score_important /= np.sum(self.score_important)

    def predict(self, X):
        estimators = np.full(X.shape[0], self.start_predict)
        for gbt_tree in self.bost_tree:
            estimators += self.learn_quan * np.array([self._predict_(x, gbt_tree) for x in X])
        return estimators

    def scatter_train_test(self, train_x, train_y, test_x, test_y):
        # Plotting For Train
        estimation_train = self.predict(train_x)
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.scatter(train_y, estimation_train, color='green', alpha=0.6)
        plt.plot([min(train_y), max(train_y)], [min(train_y), max(train_y)], color='red', linestyle='--')
        plt.title("Plotting The Scatter Plot For Training Data")
        plt.xlabel("Values Of Actual")
        plt.ylabel("Values Of Estimated")

        # Plotting For Test
        estimation_test = self.predict(test_x)
        plt.subplot(1, 2, 2)
        plt.scatter(test_y, estimation_test, color='green', alpha=0.6)
        plt.plot([min(test_y), max(test_y)], [min(test_y), max(test_y)], color='red', linestyle='--')
        plt.title("Plotting The Scatter Plot For Test Data")
        plt.xlabel("Values Of Actual")
        plt.ylabel("Values Of Estimated")
        plt.tight_layout()
        plt.show()

        # Computing The R^2
    def perform_r2(self, act_y, est_y):
        tot_s2 = np.sum((act_y - np.mean(act_y)) ** 2)
        res_s2 = np.sum((act_y - est_y) ** 2)
        return 1 - (res_s2 / tot_s2)

        # Showing The Dependency For Feature
    def showing_limited_dependency(self, X, strong_matches, noam):
        ranges = np.linspace(X[:, strong_matches].min(), X[:, strong_matches].max(), 100)
        p_ranges = []

        for val in ranges:
            x_face = X.copy()
            x_face[:, strong_matches] = val
            p_ranges.append(np.mean(self.predict(x_face)))

        plt.figure(figsize=(9, 5))
        plt.plot(ranges, p_ranges)
        plt.xlabel(f"'{noam}'Moment")
        plt.ylabel("Estimated Range")
        plt.title(f"Plotting The Limited Dependency For '{noam}'")
        plt.show()

        # Showing For Learn Curve Plot
    def showing_learn_curve(self):
        plt.figure(figsize=(9, 5))
        plt.plot(range(1, self.num_est + 1), self.train_residuals, color='blue')
        plt.xlabel("No Of Predectors")
        plt.ylabel("MSE")
        plt.title("Plotting The Curve For Learning")
        plt.show()

        # Showing For Feature Plot
    def showing_feature_noams(self, noams):
        plt.figure(figsize=(9, 5))
        plt.barh(noams, self.score_important)
        plt.xlabel("Moment")
        plt.ylabel("Feature")
        plt.title("Plotting The Significance For Feature")
        plt.show()

        # Determing The Residual For Plot Analysis
    def showing_residuals(self, X, y):
        estimators = self.predict(X)
        differences = y - estimators
        plt.figure(figsize=(9, 4))
        plt.scatter(estimators, differences, alpha=0.7, color='green')
        plt.axhline(y=0, color='red', linestyle='--')
        plt.xlabel("Estimation")
        plt.ylabel("variations")
        plt.title("Plotting For Residuals")
        plt.show()